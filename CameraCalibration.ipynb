{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Camera Calibration through OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dimensions of checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dimensions of checkerboard\n",
    " # 9,6 to begin with\n",
    "\n",
    "# Each tile is 7x7 mm\n",
    "chekcerboard_tile_size = 7 #mm\n",
    "\n",
    "CHECKERBOARD = (4,4) # Vertical, horizontal\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    " \n",
    "# Creating vector to store vectors of 3D points for each checkerboard image\n",
    "objpoints = []\n",
    "# Creating vector to store vectors of 2D points for each checkerboard image\n",
    "imgpoints = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define world coordinates for 3D points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the world coordinates for 3D points\n",
    "objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "prev_img_shape = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract path of individual image stored in ChessBoards folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to calibrate with more than one image ideally. \n",
    "images = glob.glob('./Images/ChessBoards/LimitedBoards4/*.bmp') \n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    # If desired number of corners are found in the image then ret = true\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "     \n",
    "    \"\"\"\n",
    "    If desired number of corner are detected, we refine the pixel coordinates and display them on the images of checker board\n",
    "    \"\"\"\n",
    "    \n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # refining pixel coordinates for given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "         \n",
    "        imgpoints.append(corners2)\n",
    " \n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "h,w = img.shape[:2]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration using OpenCV\n",
    "* Zhang based calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing camera calibration by passing the value of known 3D points (objpoints)\n",
    "and corresponding pixel coordinates of the detected corners (imgpoints)\n",
    "\"\"\"\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix : \\n\") # Intrinsic parameters\n",
    "print(mtx)\n",
    "print(\"\\n dist : \\n\") # [k1, k2, p1, p2, k3] k:radial distortion, p: tangential distortion\n",
    "print(dist)\n",
    "print(\"\\n rvecs : \\n\") # Extrinsic Rodriguez\n",
    "print(rvecs)\n",
    "print(\"\\n tvecs : \\n\") # Extrinsic Translation vector\n",
    "print(tvecs)\n",
    "\n",
    "print(\"tvecs[0] \", tvecs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine camera matrix and undistort images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_undistort = cv2.imread(images[0])\n",
    "\n",
    "# Refining the camera matrix:\n",
    "refined_camera_matrix, region_of_interest = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "print(\"Refined matrix: \\n\", refined_camera_matrix)\n",
    "\n",
    "# Undistortion method 1:\n",
    "distortion_1 = cv2.undistort(image_to_undistort, mtx, dist, None, refined_camera_matrix)\n",
    "cv2.imshow(\"OG image: \", image_to_undistort)\n",
    "cv2.imshow(\"Undistorted image, method 1: \", distortion_1)\n",
    "\n",
    "# Undistortion method 2:\n",
    "mapx, mapy =  cv2.initUndistortRectifyMap(mtx, dist, None, refined_camera_matrix, (w,h), 5)\n",
    "distortion_2 = cv2.remap(image_to_undistort, mapx, mapy, cv2.INTER_LINEAR)\n",
    "cv2.imshow(\"Undistorted image, method 2: \", distortion_2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate re-projection error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    image_points_2, _ = cv2.projectPoints(objpoints[i],rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i], image_points_2, cv2.NORM_L2)/len(image_points_2)\n",
    "    mean_error += error\n",
    "    \n",
    "mean_error = mean_error/len(objpoints)\n",
    "print(\"Total mean error: \", mean_error)\n",
    "\n",
    "print(\"RET from cv2.calibrateCamera: \", ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert camera matrix:\n",
    "np.linalg.inv(mtx)\n",
    "print(\"Inverted camera matrix: \\n\")\n",
    "print(mtx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Rodrigues to rotational matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix = np.zeros(shape=(3,3))\n",
    "cv2.Rodrigues(rvecs[0], rotation_matrix)\n",
    "print(\"Rotation matrix: \\n\", rotation_matrix)\n",
    "\n",
    "rotation_mask = np.array([[1, 0], [0, 1], [0, 0]])\n",
    "\n",
    "chopped_rotation = np.matmul(rotation_matrix, rotation_mask)\n",
    "# print(\"\\nChopped matrix: \\n\", chopped_rotation)\n",
    "\n",
    "extrinsic_matrix = np.hstack((chopped_rotation,tvecs[0]))\n",
    "# print(\"\\nExtrinsic matrix: \\n\", extrinsic_matrix)\n",
    "\n",
    "homography_matrix = np.matmul(mtx, extrinsic_matrix)\n",
    "print(\"\\nPre homography matrix: \\n\", homography_matrix)\n",
    "\n",
    "homography_matrix = homography_matrix/homography_matrix[2][2]\n",
    "print(\"\\nPost homography matrix: \\n\", homography_matrix)\n",
    "\n",
    "inv_homography_matrix = np.linalg.inv(homography_matrix)\n",
    "print(\"\\n Inverse homography matrix: \\n\", inv_homography_matrix)\n",
    "\n",
    "pixels = np.array((1,2,1))\n",
    "pixels = pixels.reshape(1,-1).transpose()\n",
    "print(\"Pixels: \\n\", pixels)\n",
    "\n",
    "world_coordinates = inv_homography_matrix * pixels\n",
    "print(\"\\nWorld Coordinates: \\n\", world_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for legible outputs:\n",
    "\n",
    "def calculateWorldCoordinates(pixels_to_calculate, intrinsicMatrix, extrinsicMatrix):\n",
    "    inverse_intrinsic = np.linalg.inv(intrinsicMatrix)\n",
    "    inverse_extrinsic = np.linalg.inv(extrinsicMatrix)\n",
    "    init_coords = np.dot(inverse_extrinsic, inverse_intrinsic)\n",
    "    world_coordinate_vector = np.dot(init_coords, pixels_to_calculate)\n",
    "    world_coordinate_vector = world_coordinate_vector/world_coordinate_vector[2]\n",
    "    return world_coordinate_vector\n",
    "\n",
    "pix1 = [0,0,1]\n",
    "pix2 = [3,0,0]\n",
    "pix3 = objp[0][12]\n",
    "pixels = [pix1, pix2, pix3]\n",
    "\n",
    "def coordinatesToCSV(pixels_to_calculate, intrinsicMatrix, extrinsicMatrix, outputFile):\n",
    "    # pixelCoordinates = pixelCoordinates.reshape(1,-1).transpose()\n",
    "    ok = True\n",
    "    world_coordinate_list = []\n",
    "    try: \n",
    "        outputFile = open(outputFile, \"w\")\n",
    "    except:\n",
    "        ok = False\n",
    "        print(\"Unable to open output file.\")\n",
    "    if ok:\n",
    "        outputFile.write(\"World coordinates are on the form [X, Y, Z, 1], where the '1' is left out for this file.\\n\")\n",
    "        for pixelCount,pixelCoordinate in enumerate(pixels_to_calculate):\n",
    "            outputFile.write(\"\\nPixel count: \" + str(pixelCount) + \"\\nPixel coordinates: \" + str(pixelCoordinate) + \"\\n\")\n",
    "            worldCoordinates = calculateWorldCoordinates(pixelCoordinate, intrinsicMatrix, extrinsicMatrix )\n",
    "            world_coordinate_list.append(worldCoordinates)\n",
    "            outputFile.write(\"\\nWorld coordinates: \\n\" + str(worldCoordinates) + \"\\n\")\n",
    "    \n",
    "    print(\"Written to file: \", outputFile)\n",
    "    outputFile.close()\n",
    "    return world_coordinate_list\n",
    "\n",
    "outputFile = \"Coordinates.csv\"\n",
    "world_coordinate_list = coordinatesToCSV(pixels, mtx, extrinsic_matrix, outputFile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
